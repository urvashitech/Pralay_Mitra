{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('prediction/ml/data/flood_data.db')\n",
    "\n",
    "# Handle missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "data['Station_Names'] = label_encoder.fit_transform(data['Station_Names'])\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data.drop('Flood?', axis=1))\n",
    "data_scaled = pd.DataFrame(data_scaled, columns=data.columns[:-1])\n",
    "data_scaled['Flood?'] = data['Flood?'].values\n",
    "\n",
    "# Define features and target variable\n",
    "X = data_scaled.drop('Flood?', axis=1)\n",
    "y = data_scaled['Flood?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/anujjainbatu/Desktop/flood-prediction/models/flood_prediction_model.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'prediction/ml/models/flood_prediction_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9922135706340378\n",
      "Precision: 0.9939172749391727\n",
      "Recall: 0.9975579975579976\n",
      "F1 Score: 0.9957343083485679\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "class CustomLabelEncoder(LabelEncoder):\n",
    "    def fit(self, y):\n",
    "        super().fit(y)\n",
    "        self.classes_ = np.append(self.classes_, 'unknown')\n",
    "        return self\n",
    "\n",
    "    def transform(self, y):\n",
    "        unknown_label = len(self.classes_) - 1\n",
    "        y = np.array([x if x in self.classes_ else 'unknown' for x in y])\n",
    "        return super().transform(y)\n",
    "\n",
    "    def fit_transform(self, y):\n",
    "        return self.fit(y).transform(y)\n",
    "\n",
    "# Connect to SQLite database\n",
    "conn = sqlite3.connect('prediction/ml/data/flood_data.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Fetch data from the database\n",
    "cursor.execute('SELECT Sl, Station_Names, Year, Month, Max_Temp, Min_Temp, Rainfall, Relative_Humidity, Wind_Speed, Cloud_Coverage, Bright_Sunshine, Station_Number, X_COR, Y_COR, LATITUDE, LONGITUDE, ALT, Period FROM flood_data WHERE Flood IS NULL')\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# Convert to DataFrame\n",
    "columns = ['Sl', 'Station_Names', 'Year', 'Month', 'Max_Temp', 'Min_Temp', 'Rainfall', 'Relative_Humidity', 'Wind_Speed', 'Cloud_Coverage', 'Bright_Sunshine', 'Station_Number', 'X_COR', 'Y_COR', 'LATITUDE', 'LONGITUDE', 'ALT', 'Period']\n",
    "operational_data = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "# Handle missing values\n",
    "operational_data = operational_data.dropna()\n",
    "\n",
    "# Initialize the custom label encoder\n",
    "label_encoder = CustomLabelEncoder()\n",
    "operational_data['Station_Names'] = label_encoder.fit_transform(operational_data['Station_Names'])\n",
    "\n",
    "# Encode categorical variables\n",
    "operational_data['Station_Names'] = label_encoder.transform(operational_data['Station_Names'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = joblib.load('prediction/ml/models/flood_prediction_model.pkl')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(operational_data)\n",
    "\n",
    "# Print predictions\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of required features\n",
    "required_features = ['Station_Names', 'Year', 'Month', 'Max_Temp', 'Min_Temp', 'Rainfall', 'Relative_Humidity', 'Wind_Speed', 'Cloud_Coverage', 'Bright_Sunshine', 'Station_Number', 'X_COR', 'Y_COR', 'LATITUDE', 'LONGITUDE', 'ALT']\n",
    "\n",
    "# List current features\n",
    "current_features = operational_data.columns.tolist()\n",
    "current_features.remove('Sl')\n",
    "current_features.remove('Period')\n",
    "\n",
    "# Compare features\n",
    "missing_features = set(required_features) - set(current_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9922135706340378\n",
      "Precision: 0.9939172749391727\n",
      "Recall: 0.9975579975579976\n",
      "F1 Score: 0.9957343083485679\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to the database.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = joblib.load('prediction/ml/models/flood_prediction_model.pkl')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(operational_data)\n",
    "\n",
    "# Add predictions to the operational data\n",
    "operational_data['Flood'] = predictions\n",
    "\n",
    "# Save predictions back to the database\n",
    "for index, row in operational_data.iterrows():\n",
    "    cursor.execute('''\n",
    "        UPDATE flood_data\n",
    "        SET Flood = ?\n",
    "        WHERE Sl = ?\n",
    "    ''', (row['Flood'], row['Sl']))\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Predictions saved to the database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /workspaces/Pralay_Mitra/prediction/ml/notebooks\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
